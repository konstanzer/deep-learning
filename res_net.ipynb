{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "res-net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstanzer/deep-learning/blob/master/res_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah4sfug31deR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad9ff63-8c6d-4e96-a39c-abf9f92328ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zpMivF3SGI-"
      },
      "source": [
        "# Residual Networks\n",
        "\n",
        "Welcome! You'll be building a very deep convolutional network, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by He et al., allow you to train much deeper networks than were previously feasible.\n",
        "\n",
        "By the end of this assignment, you'll be able to:\n",
        "\n",
        "    Implement the basic building blocks of ResNets in a deep neural network using Keras\n",
        "    Put together these building blocks to implement and train a state-of-the-art neural network for image classification\n",
        "    Implement a skip connection in your network\n",
        "\n",
        "For this assignment, you'll use Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMg-VDyVSHa0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x67IXfRISgML"
      },
      "source": [
        "## 2 - The Problem of Very Deep Neural Networks\n",
        "\n",
        "You've already built your first convolutional neural networks: first manually with numpy, then using Tensorflow and Keras.\n",
        "\n",
        "In recent years, neural networks have become much deeper, with state-of-the-art networks evolving from having just a few layers (e.g., AlexNet) to over a hundred layers. The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output).\n",
        "\n",
        "However, using a deeper network doesn't always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.\n",
        "\n",
        "More specifically, during gradient descent, as you backpropagate from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and \"explode,\" from gaining very large values).\n",
        "\n",
        "During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds. Not to worry! You are now going to solve this problem by building a Residual Network!\n",
        "\n",
        "## 3 - Building a Residual Network\n",
        "\n",
        "In ResNets, a \"shortcut\" or a \"skip connection\" allows the model to skip layers. The skip connection adds a shortcut tp the \"main path\" through the network. By stacking these ResNet blocks on top of each other, you can form a very deep network.\n",
        "\n",
        "Having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance. On that note, there is also some evidence that the ease of learning an identity function accounts for ResNets' remarkable performance even more than skip connections help with vanishing gradients.\n",
        "\n",
        "Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are the same or different. You are going to implement both of them: the \"identity block\" and the \"convolutional block.\"\n",
        "\n",
        "### 3.1 - The Identity Block\n",
        "\n",
        "The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). The upper path is the \"shortcut path.\" The lower path is the \"main path.\" To speed up training, a BatchNorm step is added. Don't worry about this being complicated to implement--you'll see that BatchNorm is just one line of code in Keras!\n",
        "\n",
        "In this exercise, you'll actually implement a slightly more powerful version of this identity block, in which the skip connection \"skips over\" 3 hidden layers rather than 2 layers.\n",
        "\n",
        "First component of main path:\n",
        "\n",
        "    The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: kernel_initializer = initializer(seed=0).\n",
        "    The first BatchNorm is normalizing the 'channels' axis.\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "Second component of main path:\n",
        "\n",
        "    The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random uniform initialization: kernel_initializer = initializer(seed=0).\n",
        "    The second BatchNorm is normalizing the 'channels' axis.\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "Third component of main path:\n",
        "\n",
        "    The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random uniform initialization: kernel_initializer = initializer(seed=0).\n",
        "    The third BatchNorm is normalizing the 'channels' axis.\n",
        "    Note that there is no ReLU activation function in this component.\n",
        "\n",
        "Final step:\n",
        "\n",
        "    The X_shortcut and the output from the 3rd layer X are added together.\n",
        "    Hint: The syntax will look something like Add()([var1,var2])\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "### Exercise 1 - identity_block\n",
        "\n",
        "Implement the ResNet identity block. The first component of the main path has been implemented for you already! First, you should read these docs carefully to make sure you understand what's happening. Then, implement the rest.\n",
        "\n",
        "    To implement the Conv2D step: Conv2D\n",
        "    To implement BatchNorm: BatchNormalization BatchNormalization(axis = 3)(X, training = training). If training is set to False, its weights are not updated with the new examples. I.e when the model is used in prediction mode.\n",
        "    For the activation, use: Activation('relu')(X)\n",
        "    To add the value passed forward by the shortcut: Add\n",
        "\n",
        "We have added the initializer argument to our functions. This parameter receives an initializer function like the ones included in the package tensorflow.keras.initializers or any other custom initializer. By default it will be set to random_uniform\n",
        "\n",
        "Here is where you're actually using the power of the Functional API to create a shortcut path:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoTEwOOCSWYz"
      },
      "source": [
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, \n",
        "               kernel_size = 1, \n",
        "               strides = (1,1), \n",
        "               padding = 'valid', \n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters=F2,\n",
        "               kernel_size=f,\n",
        "               strides = (1, 1),\n",
        "               padding='same',\n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, \n",
        "               kernel_size = (1,1), \n",
        "               strides = (1,1), \n",
        "               padding = 'valid', \n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3)(X, training=training)\n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7E2rnFcUd0q",
        "outputId": "1619fc03-e9fd-43e5-81cb-357437dff363"
      },
      "source": [
        "np.random.seed(1)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=False)\n",
        "print('\\033[1mWith training=False\\033[0m\\n')\n",
        "A3np = A3.numpy()\n",
        "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
        "print(resume[1, 1, 0])\n",
        "\n",
        "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
        "np.random.seed(1)\n",
        "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=True)\n",
        "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mWith training=False\u001b[0m\n",
            "\n",
            "[[[  0.        0.        0.        0.     ]\n",
            "  [  0.        0.        0.        0.     ]]\n",
            "\n",
            " [[192.71234 192.71234 192.71234  96.85617]\n",
            "  [ 96.85617  96.85617  96.85617  48.92808]]\n",
            "\n",
            " [[578.1371  578.1371  578.1371  290.5685 ]\n",
            "  [290.5685  290.5685  290.5685  146.78426]]]\n",
            "96.85617\n",
            "\n",
            "\u001b[1mWith training=True\u001b[0m\n",
            "\n",
            "[[[0.      0.      0.      0.     ]\n",
            "  [0.      0.      0.      0.     ]]\n",
            "\n",
            " [[0.40739 0.40739 0.40739 0.40739]\n",
            "  [0.40739 0.40739 0.40739 0.40739]]\n",
            "\n",
            " [[4.99991 4.99991 4.99991 3.25948]\n",
            "  [3.25948 3.25948 3.25948 2.40739]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkrhl3aVU1cu"
      },
      "source": [
        "### 3.2 - The Convolutional Block\n",
        "\n",
        "The ResNet \"convolutional block\" is the second block type. You can use this type of block when the input and output dimensions don't match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path:\n",
        "\n",
        "    The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.)\n",
        "    For example, to reduce the activation dimensions's height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2.\n",
        "    The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step.\n",
        "    As for the previous exercise, the additional initializer argument is required for grading purposes, and it has been set by default to glorot_uniform\n",
        "\n",
        "The details of the convolutional block are as follows.\n",
        "\n",
        "First component of main path:\n",
        "\n",
        "    The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". Use 0 as the glorot_uniform seed kernel_initializer = initializer(seed=0).\n",
        "    The first BatchNorm is normalizing the 'channels' axis.\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "Second component of main path:\n",
        "\n",
        "    The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is \"same\". Use 0 as the glorot_uniform seed kernel_initializer = initializer(seed=0).\n",
        "    The second BatchNorm is normalizing the 'channels' axis.\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "Third component of main path:\n",
        "\n",
        "    The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the glorot_uniform seed kernel_initializer = initializer(seed=0).\n",
        "    The third BatchNorm is normalizing the 'channels' axis. Note that there is no ReLU activation function in this component.\n",
        "\n",
        "Shortcut path:\n",
        "\n",
        "    The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". Use 0 as the glorot_uniform seed kernel_initializer = initializer(seed=0).\n",
        "    The BatchNorm is normalizing the 'channels' axis.\n",
        "\n",
        "Final step:\n",
        "\n",
        "    The shortcut and the main path values are added together.\n",
        "    Then apply the ReLU activation function. This has no hyperparameters.\n",
        "\n",
        "### Exercise 2 - convolutional_block\n",
        "\n",
        "Implement the convolutional block. The first component of the main path is already implemented; then it's your turn to implement the rest! As before, always use 0 as the seed for the random initialization, to ensure consistency with the grader.\n",
        "\n",
        "    Conv2D\n",
        "    BatchNormalization (axis: Integer, the axis that should be normalized (typically the features axis)) BatchNormalization(axis = 3)(X, training = training). If training is set to False, its weights are not updated with the new examples. I.e when the model is used in prediction mode.\n",
        "    For the activation, use: Activation('relu')(X)\n",
        "    Add\n",
        "\n",
        "We have added the initializer argument to our functions. This parameter receives an initializer function like the ones included in the package tensorflow.keras.initializers or any other custom initializer. By default it will be set to random_uniform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KtVLMUQUqSk"
      },
      "source": [
        "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
        "                   also called Xavier uniform initializer.\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    \n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, \n",
        "               kernel_size = 1, \n",
        "               strides = (s, s), \n",
        "               padding='valid', \n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, \n",
        "               kernel_size = f, \n",
        "               strides = (1,1), \n",
        "               padding = 'same', \n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, \n",
        "               kernel_size = 1, \n",
        "               strides = (1,1), \n",
        "               padding = 'valid', \n",
        "               kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training)\n",
        "    \n",
        "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, \n",
        "                        kernel_size = 1, \n",
        "                        strides = (s,s), \n",
        "                        padding = 'valid', \n",
        "                        kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrbflfsTVD_0",
        "outputId": "68e2fa4a-99f6-4d28-ace1-4cfcc8bc59cd"
      },
      "source": [
        "np.random.seed(1)\n",
        "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
        "\n",
        "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
        "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
        "\n",
        "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
        "print('\\033[92mAll tests passed!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfwY0936VTXL"
      },
      "source": [
        "## 4 - Building Your First ResNet Model (50 layers)\n",
        "\n",
        "You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. \"ID BLOCK\" in the diagram stands for \"Identity block,\" and \"ID BLOCK x3\" means you should stack 3 identity blocks together.\n",
        "\n",
        "The details of this ResNet-50 model are:\n",
        "\n",
        "    Zero-padding pads the input with a pad of (3,3)\n",
        "    Stage 1:\n",
        "        The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2).\n",
        "        BatchNorm is applied to the 'channels' axis of the input.\n",
        "        ReLU activation is applied.\n",
        "        MaxPooling uses a (3,3) window and a (2,2) stride.\n",
        "    Stage 2:\n",
        "        The convolutional block uses three sets of filters of size [64,64,256], \"f\" is 3, and \"s\" is 1.\n",
        "        The 2 identity blocks use three sets of filters of size [64,64,256], and \"f\" is 3.\n",
        "    Stage 3:\n",
        "        The convolutional block uses three sets of filters of size [128,128,512], \"f\" is 3 and \"s\" is 2.\n",
        "        The 3 identity blocks use three sets of filters of size [128,128,512] and \"f\" is 3.\n",
        "    Stage 4:\n",
        "        The convolutional block uses three sets of filters of size [256, 256, 1024], \"f\" is 3 and \"s\" is 2.\n",
        "        The 5 identity blocks use three sets of filters of size [256, 256, 1024] and \"f\" is 3.\n",
        "    Stage 5:\n",
        "        The convolutional block uses three sets of filters of size [512, 512, 2048], \"f\" is 3 and \"s\" is 2.\n",
        "        The 2 identity blocks use three sets of filters of size [512, 512, 2048] and \"f\" is 3.\n",
        "    The 2D Average Pooling uses a window of shape (2,2).\n",
        "    The 'flatten' layer doesn't have any hyperparameters.\n",
        "    The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n",
        "\n",
        "### Exercise 3 - ResNet50\n",
        "\n",
        "Implement the ResNet with 50 layers described in the figure above. We have implemented Stages 1 and 2. Please implement the rest. (The syntax for implementing Stages 3-5 should be quite similar to that of Stage 2) Make sure you follow the naming convention in the text above.\n",
        "\n",
        "You'll need to use this function:\n",
        "\n",
        "    Average pooling see reference\n",
        "\n",
        "Here are some other functions we used in the code below:\n",
        "\n",
        "    Conv2D: See reference\n",
        "    BatchNorm: See reference (axis: Integer, the axis that should be normalized (typically the features axis))\n",
        "    Zero padding: See reference\n",
        "    Max pooling: See reference\n",
        "    Fully connected layer: See reference\n",
        "    Addition: See reference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5vqtpHIVHd3"
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    \n",
        "    ## Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    \n",
        "    ## Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    ## Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D()(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZWF3CPnVlpl"
      },
      "source": [
        "Run the following code to build the model's graph. If your implementation is incorrect, you'll know it by checking your accuracy when running model.fit(...) below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBHXD6gIVf24",
        "outputId": "9b0bd472-f344-4743-ba55-3d028ec46508"
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 15, 15, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 15, 15, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 15, 15, 64)   36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 15, 15, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 15, 15, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 15, 15, 256)  16640       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 15, 15, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 15, 15, 256)  1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 15, 15, 256)  0           batch_normalization_17[0][0]     \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 15, 15, 256)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 15, 15, 64)   16448       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 15, 15, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 15, 15, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 15, 15, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 15, 15, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 15, 15, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 15, 15, 256)  16640       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 15, 15, 256)  1024        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 15, 15, 256)  0           activation_15[0][0]              \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 15, 15, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 15, 15, 64)   16448       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 15, 15, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 15, 15, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 15, 15, 64)   36928       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 15, 15, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 15, 15, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 15, 15, 256)  16640       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 15, 15, 256)  1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 15, 15, 256)  0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 15, 15, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 128)    32896       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 128)    512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 128)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 128)    147584      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 512)    66048       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 512)    131584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 512)    2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 512)    2048        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 512)    0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 128)    65664       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 512)    66048       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 512)    2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 512)    0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 512)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 128)    65664       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147584      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 128)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 512)    66048       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 512)    2048        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 512)    0           activation_27[0][0]              \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 512)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 128)    65664       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 128)    147584      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    66048       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 512)    0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 512)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 256)    131328      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 256)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 1024)   525312      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 1024)   4096        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 4, 4, 1024)   4096        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_40[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 4, 4, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 256)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 256)    1024        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 256)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 1024)   4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 4, 1024)   0           activation_36[0][0]              \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 256)    262400      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 256)    1024        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 256)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 256)    590080      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 256)    1024        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 256)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 1024)   263168      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 1024)   4096        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 1024)   0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 256)    1024        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 256)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 256)    1024        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 256)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 1024)   4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 4, 1024)   0           activation_42[0][0]              \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 1024)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 256)    262400      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 256)    1024        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 256)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 256)    590080      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 256)    1024        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 256)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 1024)   263168      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 4, 4, 1024)   4096        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 4, 1024)   0           activation_45[0][0]              \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 1024)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 256)    262400      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 4, 4, 256)    1024        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 256)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 256)    590080      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 4, 4, 256)    1024        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 4, 4, 256)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 4, 4, 1024)   263168      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 4, 4, 1024)   4096        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 4, 4, 1024)   0           activation_48[0][0]              \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 4, 4, 1024)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 2, 2, 512)    524800      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 2, 2, 512)    2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 2, 2, 512)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 2, 2, 512)    2359808     activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 2, 2, 512)    2048        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 2, 2, 512)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 2, 2, 2048)   2099200     activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 2, 2, 2048)   8192        conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 2, 2, 2048)   8192        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_59[0][0]     \n",
            "                                                                 batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 2, 2, 2048)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 2, 2, 512)    1049088     activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 2, 2, 512)    2048        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 2, 2, 512)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 2, 2, 512)    2359808     activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 2, 2, 512)    2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 2, 2, 512)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 2, 2, 2048)   8192        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 2, 2, 2048)   0           activation_54[0][0]              \n",
            "                                                                 batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 2, 2, 2048)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 2, 2, 512)    1049088     activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 2, 2, 512)    2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 2, 2, 512)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 2, 2, 512)    2359808     activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 2, 2, 512)    2048        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 2, 2, 512)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 2, 2, 2048)   8192        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 2, 2, 2048)   0           activation_57[0][0]              \n",
            "                                                                 batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 2, 2, 2048)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 6)            12294       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r7hFPlZVozf"
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4UBaHqYV37h"
      },
      "source": [
        "As shown in the Keras Tutorial Notebook, prior to training a model, you need to configure the learning process by compiling the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlCEnq1kVwxL"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5pOihEeV7Nj"
      },
      "source": [
        "\n",
        "\n",
        "The model is now ready to be trained. The only thing you need now is a dataset!\n",
        "\n",
        "Let's load your old friend, the SIGNS dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdfxL12zbKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad1658b-bcc8-407d-b9a2-dae23e782f85"
      },
      "source": [
        "import h5py\n",
        "#https://www.kaggle.com/ayanmaity/hand-sign-resnet\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "from subprocess import check_output\n",
        "\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/data/handsigns/\"\n",
        "print(check_output([\"ls\", path]).decode(\"utf8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_hands\n",
            "resnet50.h5\n",
            "test_signs.h5\n",
            "train_signs.h5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytsMFkGiyp95"
      },
      "source": [
        "def load_dataset():\n",
        "  train_dataset = h5py.File(path+'train_signs.h5', \"r\")\n",
        "\n",
        "  #x_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_x'])\n",
        "  #y_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_y'])\n",
        "\n",
        "  #x_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_x'])\n",
        "  #y_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_y'])\n",
        "\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "  test_dataset = h5py.File(path+'test_signs.h5', \"r\")\n",
        "  test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "  test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "\n",
        "  classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "  \n",
        "  return train_set_x_orig, train_set_y_orig.T, test_set_x_orig, test_set_y_orig.T, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dtqt6FPV6R2",
        "outputId": "75c6afcb-b424-46ca-fd12-6272e893ce82"
      },
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = np.array(tf.one_hot(Y_train_orig, 6)) #tensor to array, IDK\n",
        "Y_test = np.array(tf.one_hot(Y_test_orig, 6))\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIoIQFGBAHoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "11c645d0-c214-48c1-d91a-c535f50bceb1"
      },
      "source": [
        "imshow(X_train_orig[0])\n",
        "plt.show()\n",
        "imshow(X_train_orig[1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa3LCLpZ4vMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d73fc31d-d6c2-4456-f294-f36573db0008"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "34/34 [==============================] - 13s 149ms/step - loss: 1.8875 - accuracy: 0.4593\n",
            "Epoch 2/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.4828 - accuracy: 0.8324\n",
            "Epoch 3/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.3361 - accuracy: 0.8843\n",
            "Epoch 4/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.2659 - accuracy: 0.9148\n",
            "Epoch 5/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.5883 - accuracy: 0.8500\n",
            "Epoch 6/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 1.1407 - accuracy: 0.7259\n",
            "Epoch 7/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.8213 - accuracy: 0.7917\n",
            "Epoch 8/20\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.3210 - accuracy: 0.8907\n",
            "Epoch 9/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.1479 - accuracy: 0.9602\n",
            "Epoch 10/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.1360 - accuracy: 0.9602\n",
            "Epoch 11/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.1432 - accuracy: 0.9500\n",
            "Epoch 12/20\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.1211 - accuracy: 0.9593\n",
            "Epoch 13/20\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.0579 - accuracy: 0.9787\n",
            "Epoch 14/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0489 - accuracy: 0.9833\n",
            "Epoch 15/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0462 - accuracy: 0.9870\n",
            "Epoch 16/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0274 - accuracy: 0.9907\n",
            "Epoch 17/20\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.0248 - accuracy: 0.9917\n",
            "Epoch 18/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0510 - accuracy: 0.9880\n",
            "Epoch 19/20\n",
            "34/34 [==============================] - 4s 132ms/step - loss: 0.0872 - accuracy: 0.9722\n",
            "Epoch 20/20\n",
            "34/34 [==============================] - 4s 131ms/step - loss: 0.0545 - accuracy: 0.9815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e4e12e410>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsKuYk-B4kO"
      },
      "source": [
        "\n",
        "Congratulations on finishing this assignment! You've now implemented a state-of-the-art image classification system! Woo hoo!\n",
        "\n",
        "ResNet50 is a powerful model for image classification when it's trained for an adequate number of iterations. Hopefully, from this point, you can use what you've learned and apply it to your own classification problem to perform state-of-the-art accuracy.\n",
        "\n",
        "\n",
        "\n",
        "What you should remember:\n",
        "\n",
        "    Very deep \"plain\" networks don't work in practice because vanishing gradients make them hard to train.\n",
        "    Skip connections help address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function.\n",
        "    There are two main types of blocks: The identity block and the convolutional block.\n",
        "    Very deep Residual Networks are built by stacking these blocks together.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni_5jV_4DzR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bda2ae2-6f99-449c-841d-e6ef358d7eb8"
      },
      "source": [
        "model.save(path+\"resnet50.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A6LVcoNDKS_"
      },
      "source": [
        "model = tf.keras.models.load_model(path+'resnet50.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooD_MmbT9WGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bbb3647-0b70-494f-d648-53c321df27ed"
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 64ms/step - loss: 0.1073 - accuracy: 0.9750\n",
            "Loss = 0.10733150690793991\n",
            "Test Accuracy = 0.9750000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Vf9qpBCi_d"
      },
      "source": [
        "## 5 - Test on Your Own Image\n",
        "\n",
        "If you wish, you can also take a picture of your own hand and see the output of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R2zDyq0B5JP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c39a145a-98db-4eec-bb83-ad4f51ca76b6"
      },
      "source": [
        "img_path = path+'my_hands/four.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "print('Input image shape:', x.shape)\n",
        "imshow(img)\n",
        "prediction = model.predict(x)\n",
        "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", np.round(prediction,3))\n",
        "print(\"Class:\", np.argmax(prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input image shape: (1, 64, 64, 3)\n",
            "Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] =  [[0.539 0.002 0.002 0.217 0.2   0.04 ]]\n",
            "Class: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dJTSL6VCtOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2fc669-c147-4e94-c260-7a8c7c62d1f2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 70, 70, 3)    0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 32, 32, 64)   9472        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 64)   256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 32, 32, 64)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 64)   0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 15, 15, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 15, 15, 64)   256         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 15, 15, 64)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 15, 15, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 15, 15, 64)   256         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 15, 15, 64)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 15, 15, 256)  16640       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 15, 15, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 15, 15, 256)  1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 15, 15, 256)  1024        conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 15, 15, 256)  0           batch_normalization_70[0][0]     \n",
            "                                                                 batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 15, 15, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 15, 15, 64)   16448       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 15, 15, 64)   256         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 15, 15, 64)   0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 15, 15, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 15, 15, 64)   256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 15, 15, 64)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 15, 15, 256)  16640       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 15, 15, 256)  1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 15, 15, 256)  0           activation_64[0][0]              \n",
            "                                                                 batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 15, 15, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 15, 15, 64)   16448       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 15, 15, 64)   256         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 15, 15, 64)   0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 15, 15, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 15, 15, 64)   256         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 15, 15, 64)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 15, 15, 256)  16640       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 15, 15, 256)  1024        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 15, 15, 256)  0           activation_67[0][0]              \n",
            "                                                                 batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 15, 15, 256)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 128)    32896       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 128)    512         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 128)    147584      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 128)    512         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 8, 8, 128)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 512)    66048       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 512)    131584      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 512)    2048        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 512)    2048        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 512)    0           batch_normalization_80[0][0]     \n",
            "                                                                 batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 512)    0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 128)    65664       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 128)    512         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 128)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 128)    147584      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 128)    512         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 128)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 512)    66048       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 512)    2048        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 512)    0           activation_73[0][0]              \n",
            "                                                                 batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 512)    0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 128)    65664       activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 128)    512         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 128)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 128)    147584      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 128)    512         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 128)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 512)    66048       activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 512)    2048        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 512)    0           activation_76[0][0]              \n",
            "                                                                 batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 512)    0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 128)    65664       activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 128)    512         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 128)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 128)    147584      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 128)    512         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 128)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 512)    66048       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 512)    2048        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 512)    0           activation_79[0][0]              \n",
            "                                                                 batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 512)    0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    131328      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 4, 4, 256)    1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 256)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 4, 4, 256)    1024        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 256)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 4, 4, 1024)   263168      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 1024)   525312      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 4, 4, 1024)   4096        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 4, 4, 1024)   4096        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_93[0][0]     \n",
            "                                                                 batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    262400      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 4, 4, 256)    1024        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 256)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 256)    590080      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 4, 4, 256)    1024        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 4, 4, 256)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 4, 4, 1024)   263168      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 4, 4, 1024)   4096        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 1024)   0           activation_85[0][0]              \n",
            "                                                                 batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 4, 4, 256)    262400      activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 4, 4, 256)    1024        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 4, 4, 256)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 4, 4, 256)    590080      activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 4, 4, 256)    1024        conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 4, 4, 256)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 4, 4, 1024)   263168      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 4, 4, 1024)   4096        conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 4, 4, 1024)   0           activation_88[0][0]              \n",
            "                                                                 batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 4, 4, 1024)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 4, 4, 256)    262400      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 4, 4, 256)    1024        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 4, 4, 256)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 4, 4, 256)    590080      activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 4, 4, 256)    1024        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 4, 4, 256)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 4, 4, 1024)   263168      activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 4, 4, 1024)   4096        conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 4, 4, 1024)   0           activation_91[0][0]              \n",
            "                                                                 batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 4, 4, 1024)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 4, 4, 256)    262400      activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 4, 4, 256)    1024        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 4, 4, 256)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 4, 4, 256)    590080      activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 4, 4, 256)    1024        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 4, 4, 256)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 4, 4, 1024)   263168      activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 4, 4, 1024)   4096        conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 4, 4, 1024)   0           activation_94[0][0]              \n",
            "                                                                 batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 4, 4, 1024)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 4, 4, 256)    262400      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 4, 4, 256)    1024        conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 4, 4, 256)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 4, 4, 256)    590080      activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 4, 4, 256)    1024        conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 4, 4, 256)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 4, 4, 1024)   263168      activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 4, 4, 1024)   4096        conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 4, 4, 1024)   0           activation_97[0][0]              \n",
            "                                                                 batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 4, 4, 1024)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 2, 2, 512)    524800      activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 2, 2, 512)    2048        conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 2, 2, 512)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 2, 2, 512)    2359808     activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 2, 2, 512)    2048        conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 2, 2, 512)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 2, 2, 2048)   2099200     activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 2, 2, 2048)   8192        conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 2, 2, 2048)   8192        conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_112[0][0]    \n",
            "                                                                 batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 2, 2, 2048)   0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 2, 2, 512)    1049088     activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 2, 2, 512)    2048        conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 2, 2, 512)    0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 2, 2, 512)    2359808     activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 2, 2, 512)    2048        conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 2, 2, 512)    0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 2, 2, 2048)   8192        conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 2, 2, 2048)   0           activation_103[0][0]             \n",
            "                                                                 batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 2, 2, 2048)   0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 2, 2, 512)    1049088     activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 2, 2, 512)    2048        conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 2, 2, 512)    0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 2, 2, 512)    2359808     activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 2, 2, 512)    2048        conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 2, 2, 512)    0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 2, 2, 2048)   8192        conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 2, 2, 2048)   0           activation_106[0][0]             \n",
            "                                                                 batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 2, 2, 2048)   0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            12294       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3iyWvUDCtqr"
      },
      "source": [
        "## 6 - Bibliography\n",
        "\n",
        "This notebook presents the ResNet algorithm from He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the GitHub repository of Francois Chollet:\n",
        "\n",
        "    Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - Deep Residual Learning for Image Recognition (2015)\n",
        "    Francois Chollet's GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLEyD1H7CwOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
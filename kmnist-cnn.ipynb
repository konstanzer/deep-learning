{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmnist_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRuK3lgR39Q0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksaoi3uU5QL8"
      },
      "source": [
        "Kuzushiji-MNIST is a drop-in replacement for the MNIST dataset (28x28 grayscale, 70,000 images), provided in the original MNIST format as well as a NumPy format. Since MNIST restricts us to 10 classes, we chose one character to represent each of the 10 rows of Hiragana when creating Kuzushiji-MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "260710c89694486aa3376acd0de4fe0a"
          ]
        },
        "id": "7MwO9XcR3_bM",
        "outputId": "6569d506-acbb-4a28-813a-bcde6b8a49e4"
      },
      "source": [
        "ds, ds_info = tfds.load('kmnist', as_supervised=True, with_info=True)\n",
        "ds_info"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/kmnist/3.0.1.incompleteQPZD6T/kmnist-test.tfrecord\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "260710c89694486aa3376acd0de4fe0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset kmnist downloaded and prepared to /root/tensorflow_datasets/kmnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='kmnist',\n",
              "    version=3.0.1,\n",
              "    description='Kuzushiji-MNIST is a drop-in replacement for the MNIST dataset (28x28 grayscale, 70,000 images), provided in the original MNIST format as well as a NumPy format. Since MNIST restricts us to 10 classes, we chose one character to represent each of the 10 rows of Hiragana when creating Kuzushiji-MNIST.',\n",
              "    homepage='http://codh.rois.ac.jp/kmnist/index.html.en',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
              "    }),\n",
              "    total_num_examples=70000,\n",
              "    splits={\n",
              "        'test': 10000,\n",
              "        'train': 60000,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@online{clanuwat2018deep,\n",
              "      author       = {Tarin Clanuwat and Mikel Bober-Irizar and Asanobu Kitamoto and Alex Lamb and Kazuaki Yamamoto and David Ha},\n",
              "      title        = {Deep Learning for Classical Japanese Literature},\n",
              "      date         = {2018-12-03},\n",
              "      year         = {2018},\n",
              "      eprintclass  = {cs.CV},\n",
              "      eprinttype   = {arXiv},\n",
              "      eprint       = {cs.CV/1812.01718},\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "9o_nVX9T7_3g",
        "outputId": "d6cb0218-a79d-498a-8d41-a28df7e40dfa"
      },
      "source": [
        "tfds.as_dataframe(ds['train'].take(10), ds_info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >image</th>        <th class=\"col_heading level0 col1\" >label</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABf0lEQVR4nGNggAHR1QtNGOE8NiY4k4FLXqHz//+PXfZIYnBQ/uzDz////389z4dF0uHR////z4QY82KRY2AwW/LvgwFWGQYGBgb130cx7IMJMFUzn/mHQx9zx88XCuw4JFV//n89f3+9LlxAWBhhePn/////////2gdqUOOL2zA5pTUf/v//8/Tuq//rmRgYGBi4M3//fwaVY1v8//+/27lqGq3/P0swMDC6n/32YYsVVDLs5+91YcKMDAwyn/+nMGrO+fqqWp4FZmrDfH8Im+32/0fTTv5YaYOIAARgXPD//9/rwazYfRTz/4WbEA7fMjj97UPmooQntw8jNy596if+/r/PgV2Oc9n///8v8WA3NkD5OwPDxi9YNRrtEw/+9z8Lu4O8JX9c/stwF6sko2ztp2+fGUwZGNjFOdEl5d3e/P/6lUEzI2fdsRlKaFZa/3zQWPDp/+//////f5qHJimy/C8kwr8+f9ZhDLUK4c12d8kf5xWuLXj69+YPiBAAvLWbx8Ue7g4AAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row0_col1\" class=\"data row0 col1\" >9 (wo)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABeUlEQVR4nHWQP0gCURzHv89TNO0whTBJUDqCqEHhamgoaYmgwKWmGhxqKKjNSVqaIppqKxwisKBwiYTmoKEt+q9FEhcVZGHWiZ13r8GjPL17yw++n/d5v9/vAQCAQoUHTOt34w40ntUNBkBoL5/16VD18OKSMTSlMhZj2v/N1VzViryACV3JFYqdSI9S+j8h1WLjOyJDTgZQMrbuUp0VPi9RKp0l5oNs9nKKI1pqDkTnuhgA2KRSebe+JXsasQJwJGWZXqvGHyymU5mbB1+II6Q42TCtdVmhlNJKnq6g3kQ5fhw0ixcF9sivuyoAICC+2A2hKS1P66Q2azNjIey+Imh7Ng0P+ttcFtcTfevxgq2G6l9wO70EYu5LavXZAXw6a188oJTS9+UgIe0D8fvKlqZd7Cq5digoOTcB4Agz2mEIADZFw9oJ1UoBFM0oGy7o/RA8uiYAZqEl8WokjlVu3UbM8yxHAZDR7cW+BjgjzxIAI4UfpdRZjX4BJ453CBHV8H4AAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1 (ki)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABVklEQVR4nNWRTSjDcRzGP78222GLUcprkbLk4CUvBwkl7zk4UEspcpCD1HZQcuC0wkm5IAcnpSSpKbnIhYNWyrISmdBs8t8w89/XTa1x5zk9PS/fw/OF/4qqnSFDkqC+mcHhTrf4Fw4KSrKt9++em6RYg359JSKS+IhHIxKa7zR+1wwmj+hvbx8i3prKoqLZiHw6laroebGbKHvReiNuz3vTCmsjgBpdMmrVxqBlJrzM5VSmzCxAB9wCyEpsMasfzLUFipw7ObAALpEJAGV3Psm9kdgJZKzmauNRYJDPaJ2t0DBZbIY9APKOEnJc3+eaLr8Q0UUkoYvET/MV0DrdBIjExeT1lYWtr4HDiDnhO9cAtkXkebClrs0fKk3aBWBdtoarIH8/3JU63oaMAc0PMpdcAqDRkQndQX3X9stH2gOhgbSfrZzNuDaSKisAVWvj8eyXm38JX3K7ieOsHGuwAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row2_col1\" class=\"data row2 col1\" >7 (ya)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABwElEQVR4nG1SMUwTYRh9d+1R2qbURECEdjEsdCAQqiRGLOJkTFgIJBrjICvRMDCoLLIJCwmDi4FBFoYm6mRkAQzahDBYjQaNjZhYSaGEo+2V/r3rc2g9y919y5e89/3vvXz/B5glx/bIlwqcSpnWyK1YPeSudSkYfeQ1ZjuKDqQ0dUn76O5bTzQ7aEbVozdtkxzxXLsi2cjhQmlEGWX2fVncspGRHZFcS5Hkcl2kmmdaknz+duQmMmsndtOWaPuZX9RCp0C52pqGRMbvg9fnEPbB1kkhsVrhcdMpuOq5p/4MXpSBkqcm1KCWzZEFlm7c29+nHgGAc/2J7GOX+Xw1r571dIfn7riAzqc/BLnb+Y8cEHqiOin3PMmSxuf7jaZnSClvGoA8cPv8YAD4NBfX/gfqgZKXm6NjY17muf1iKVeXWNkWheebaYNkKb1o+W3fjl4RJMnj1yHZsgL3B4MkK4czQw5H8rBc3C2SSZedApRYb+sr8pkTBwBYJC9bMdM/A0SspHkx1+PBg/jb37y64glf2PhumbqrC2GIYuWbqnPBIsv1+bySOjjSW1UZXy2ygNR180tucPxPQyAw+g4A8BfNKLjjFAbYkwAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row3_col1\" class=\"data row3 col1\" >2 (su)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row4_col0\" class=\"data row4 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB3UlEQVR4nG2QX0hTYRjGn3N2draDZ0tFM2thgygQg/xDihYWdOFtgRloCF31hy4i6C4jvPJKKIuooD9gREEgolAQRoJ1lVGQroiZiZVjsq152tnpO48XU+fa914+v+95vvd9AADA4W+8okE6evu89TL5tlOVMN/z9MxZ4xb/tEqgd4SLjdidWnliSuhR58fdQ+bNBeeGrxia06Q9M58S7JRYD3wnycSw+zkooR0JkpzKiiHJxp4um9Grg7/45UgxrLvjcMzvO22LWO3/7GBEcLwO0O8L0acUMu01rWchAKiepD16vsHYBL2Toi+gAkDLBEk6S+8uewDkMrofzC29L4mVieZdpTnlb8ebjRZu265LuuK3lY6RLlORMxtOKHu2mzv/LS/GmzIX2oFXPXGn+CRvWKv9RE6XSoqCCvgfkuJFeaGuB4I1VU3hhlMfSXJAzf+ptp0L1Sjltin0jAgAiO5PARoAKOHjF1WkfyazlYblD4AZr+NZT6yPsn9rRVAv8ZVVbQufePwhLZZDa8x4GpkoqNvY13ttfd+e5EldtjpUAHs9A4+aDQDQzC1Q8g81AAmtuuvY7KxaMVXZGozruHdd5N1tCxZzkyTp0mrZnL2jey5rfXVIuiTJS2v6KtgL0Oqj2ZWGAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row4_col1\" class=\"data row4 col1\" >1 (ki)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row5_col0\" class=\"data row5 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABTUlEQVR4nGNgQAVMCRWiDGwM2AFX6P/DWvxQDguE0na88/nzvW+8X7gE/1isjL0AEWWEUOzVRoYCt1+wcEszsoj+WFP/EFmSgYFB3FFO+6uDNDfzj/MHry5Bt47dRU9M12TD/086nDDXIST//n33/frHWwxsIpju5GXlZGJkl5R8+kmFBUPnF8bv//7/+frpDevfPxiSjGr8TAzMX1j+foKLIST/PfnCzfyfW5xThAVTkuHDX1F2PlElMbipyJIMDC//iP38zMcKdy0LsuRXhs+CnH9YxDG9wsDAwMCQ9PzXp//u2OXY7vx/ffWzGlY7Gf6+ZvjE8fwxDsnM7/ycfzlw2MmQ8+LtCy5ckoxT/59ixiUpdutfCC45Bu+/+9lxybHd+GmH08aKfwsYcUkm/Fyiw4RDzu5FpJEAdimZnKV6DLj0LatgZmBgRJYFAHV6Z6ePxyRAAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row5_col1\" class=\"data row5 col1\" >2 (su)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row6_col0\" class=\"data row6 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABuElEQVR4nGNggALFu48kGHAA1vVfvXDJMXj97WbGKTnjgRKmIBOUZhGaw4JTp8fbXy44JQU+bNdhYGBgYNBfOd0K3fSce1kMDAwMDGI7v757b4wqKf//tSgDAwMD7+3Fya/+7RJDkez93szAwMDAsPu9M3fu53ttyHLC71+JMTAwMKQ/yGNkULnzdw+Sn9mP/WtnYGBgMPvxXZOBge3hn18eCEnjzz/dGRgY+C5fiWdgYHD6fnvGNoSkzM1fz+YLMhT9n8fAwBB9/eauFkMkO+XmPvyfZ/v2ayyDzZvVc8I4GFH9IlL25e2/SiaDZ3M1rTDCUWz+z387eVkPrsIWwozWT84LMsT/70QWhCl0rzi86j3Dq9+/GRgYGBj/QwShUSY4TffXTgYGTlYRBgYGpv8MDGyINMN88P9jcQYGhr3/77AxM2lL1K19/UYBJhn4ep8yAwMD4+mff8/uvv746tM3D37OghqrOPnQxnsMDAz/j/37J89x494t/q2rbj1mYGBkYGBg38gzeSUkMBpEnvT5s20SYbry7SvE0FlvJsKSEhMDGii/v08Wi88hYN5DTZxyDEYNuGQAEJyTferJAMEAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row6_col1\" class=\"data row6 col1\" >1 (ki)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row7_col0\" class=\"data row7 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpElEQVR4nGNgYGBgYJAvefOlQ4aVgYGBteLbm19bolkZkAD3ov/vHRgYGNgW//2/r5WLARXw7Pn3bXFI3fbvl47ZMWAA5cf//nz4dq8znRVTjoHB49f/L88fcSMLMcFZQszrc1gY/mLTx2C1dTqX2f/HLFh1fngg9P/FfyklrDoZ5C4c2fznvyZ2O5/+ttb+zKCAVZKtUHCF2RoGUWyGMmf8rWdncP3vik3nv4dPHv5m+PufGZtOjv3/Hp2L6ftfidWxkhfP//v5918Ldq+o/nr+dfOvBVhdy2j+Xag69cAbrBr57/zfzMa8cX/TfGUssov/tNmGXf3z//9rUww55gn/f7z4c/n999/fomFisFhgj41n+CGw8fXbnT+fPoe7g4GBgYGBzzTR6gvnwyP7jv/GMJJl5ZE4GV4+OJcdxb6zh+EGcQtZnL8XxYZk7C5pE2ZpNdbnpfee5tzRk2D4cyjxEdxBL51v8HGd0fnJwPlCRubbZ94/gqqP4Dr9V7MyfGV/+1vmx23t93tvfttz/i/CWOZFfox/3tcZ/JT6wtoA9wkDAH8EpY1ANzMPAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row7_col1\" class=\"data row7 col1\" >8 (re)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row8_col0\" class=\"data row8 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABj0lEQVR4nG2PyytEcRTHv787dx40xpi8N+Q1iomkUISNR6E8NhYWpsSGhbISNv4DZaMskGJjQU1T3lbemmYWU96PGuNtmDvDNcdi4sr8zurb+fT9nu8BlNFUuF3d7M9CUGTi2Lrx8J7AGVbidC17Zd9QDIeNSKO6aYlIruXEWjQU7GpaC6oMnNh6z246g3aJajkwes7vWx6MPqFWbqPWy3eb4ZgaedB4cNMfH+sNVfGMi9YoBrb/WcZpqy8+lQgkQqNA8Uf4dmYnnhauZPmRdzP/kui83O238CDy78gRt02TIg+aXB6rbvtLHuDBhsBZjNZOFJzP/t8WrFrLMnvxAVWLOcKocZLsPdoL+Fc71REwa+tWDr1vWLOFCKRufn2RnufboiK7sFLbxd14Xxb3RWvg2p3MuAhsa0HPe10AAFPa05us7MSCUlNYAMDrTJIqRAAY0+vL2nPNqs26AIDwITaV4VnJMatTTAlMAICXvBslyZBaM/RAkkTh8fcI+HUCAIoqvwo7ROAzZB92EAB8A3qxlRUDuE2wAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row8_col1\" class=\"data row8 col1\" >8 (re)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row9_col0\" class=\"data row9 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8ElEQVR4nGNgQAELZvMy4ALs7//nInGZUCR/nmCwwCnJ0PeLA6ck697nP5C4LHAWo6Srt9UFLh2mf5huYQ7x2nN1muOrt3rY3erIycD0vHAVMxYppjZhBgbur5Lvi7E46N/Lk8lC2j+FP2diM5Up8NKnp3///p+B3VJ2lZLnRRGc2CUZGMI2oZiFKqlyCY+k/EM8klIfcUsyyj7F5RqGiG1/unVxyIX8/f///3cX7MaG/P/5MZsjGrtOtef/cmX+ncNhrqIbU/D/fTidxLDwfx5OOZZXB9hwSsb/wuUVBgb+W5Nx29j0QgKnnOVXbxQ+AFj/R+Lm+dVwAAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
              "                        <td id=\"T_339248e4_3cb5_11ec_b01a_0242ac1c0002row9_col1\" class=\"data row9 col1\" >6 (ma)</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "                                               image  label\n",
              "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      9\n",
              "1  [[[0], [0], [0], [0], [0], [0], [241], [252], ...      1\n",
              "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7\n",
              "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      2\n",
              "4  [[[0], [0], [0], [0], [0], [0], [64], [221], [...      1\n",
              "5  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      2\n",
              "6  [[[0], [0], [0], [0], [0], [0], [0], [0], [33]...      1\n",
              "7  [[[0], [0], [0], [0], [0], [31], [116], [236],...      8\n",
              "8  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      8\n",
              "9  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      6"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax1OY5SjDKu8"
      },
      "source": [
        "def normalize(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQUD_sM6D0BR",
        "outputId": "e0b6ae95-3da0-43dc-f4fa-198668f53851"
      },
      "source": [
        "ds_train = ds['train'].map(normalize).batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds['test'].map(normalize).batch(128).prefetch(tf.data.AUTOTUNE)\n",
        "ds_train.element_spec"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NzbIw06LwLm"
      },
      "source": [
        "def define_model(filters, kernel_size, input_shape, pool_size, nodes):\n",
        "  \"\"\"Based on a model by Francois Chollet https://github.com/fchollet/deep-learning-with-python-notebooks\n",
        "  \"\"\"\n",
        "  model = Sequential()  # model is a linear stack of layers\n",
        "  #convolutional layers and dense layers require an activation function\n",
        "  model.add(Conv2D(filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   padding='valid',\n",
        "                   input_shape=input_shape,\n",
        "                   activation='relu'))  #first conv. layer  KEEP\n",
        "  model.add(Conv2D(filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   padding='valid',\n",
        "                   activation='relu'))  #2nd conv. layer  KEEP\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=pool_size)) #decreases size, prevent overfitting\n",
        "  model.add(Dropout(0.5))  #zeros out some fraction of inputs, prevent overfitting\n",
        "  model.add(Flatten())  #must flatten before going into conventional dense layer  KEEP\n",
        "  print('Model flattened out to ', model.output_shape)\n",
        "\n",
        "  #now start a typical neural network\n",
        "  model.add(Dense(nodes, activation='relu'))  #change neurons in this layer\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(n_classes, activation='softmax'))  #10 final nodes (one for each class)  KEEP\n",
        "  #softmax at end to pick between classes 0-9 KEEP\n",
        "\n",
        "  # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
        "  # suggest you KEEP loss at 'categorical_crossentropy' for multi-class problem\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer = Adam(learning_rate=0.001),\n",
        "                metrics=['sparse_categorical_accuracy']) #multi-label integers (not OHE)\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSEJTu_CFBcS",
        "outputId": "b8a7f62d-ee49-450e-f0a5-372e589490ce"
      },
      "source": [
        "#a small batch size is key\n",
        "batch_size = 32  #number of training samples used at a time to update the weights\n",
        "n_classes = 10    #number of output possibilities: [0 - 9] KEEP\n",
        "epochs = 6   #number of passes through the entire train dataset before weights \"final\"\n",
        "input_shape = (28, 28, 1)   # px x px x 1 channel image input (grayscale) KEEP\n",
        "filters = 24    #number of convolutional filters to use\n",
        "pool_size = (2, 2)  #pooling decreases image size, reduces computation, adds translational invariance\n",
        "kernel_size = (4, 4)  #convolutional kernel size, slides over image to learn features\n",
        "nodes = 512  #neurons in dense layer\n",
        "\n",
        "model = define_model(filters, kernel_size, input_shape, pool_size, nodes)\n",
        "# during fit process watch train and test error simultaneously\n",
        "model.fit(ds_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(ds_test))\n",
        "\n",
        "score = model.evaluate(ds_test, verbose=0)\n",
        "print('Test cross-entropy score:', score[0])\n",
        "print('Test cross-entropy accuracy:', score[1])  # this is the one we care about"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model flattened out to  (None, 2904)\n",
            "Epoch 1/6\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3786 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.3162 - val_sparse_categorical_accuracy: 0.9053\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1414 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.2451 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.1984 - val_sparse_categorical_accuracy: 0.9432\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9481\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1699 - val_sparse_categorical_accuracy: 0.9529\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.1524 - val_sparse_categorical_accuracy: 0.9589\n",
            "Test cross-entropy score: 0.1524088829755783\n",
            "Test cross-entropy accuracy: 0.958899974822998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__yYF5o_SGpr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}